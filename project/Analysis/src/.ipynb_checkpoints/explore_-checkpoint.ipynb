{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from classifiers import *\n",
    "from FeatureSelection import *\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = np.load(\"../Data/vectorized_data.npz\")\n",
    "except:\n",
    "    os.system(\"python clean_data.py\")\n",
    "    data = np.load(\"../Data/vectorized_data\")\n",
    "    \n",
    "train_tfidf,train_labels = data['arr_0'], data['arr_1']\n",
    "test_tfidf,test_labels = data['arr_2'], data['arr_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "(2343, 68545)\n",
      "(2343,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Training data\")\n",
    "print (train_tfidf.shape)\n",
    "print (train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data\n",
      "(1560, 68545)\n",
      "(1560,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data\")\n",
    "print (test_tfidf.shape)\n",
    "print (test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. K = 55, NPC = 2343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_PC = np.load(\"data_dump/train_data_tfidf_PC_2343.npy\")\n",
    "test_PC = np.load(\"data_dump/test_data_tfidf_PC_2343.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNN_classifier(param = 55)\n",
    "classifier.train(train_PC,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = classifier.predict(test_PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           comp.graphics       0.83      0.83      0.83       389\n",
      " comp.os.ms-windows.misc       0.78      0.78      0.78       394\n",
      "comp.sys.ibm.pc.hardware       0.70      0.71      0.71       392\n",
      "   comp.sys.mac.hardware       0.75      0.74      0.75       385\n",
      "\n",
      "               micro avg       0.77      0.77      0.77      1560\n",
      "               macro avg       0.77      0.77      0.77      1560\n",
      "            weighted avg       0.77      0.77      0.77      1560\n",
      "\n",
      "Confusion Matrix:\n",
      "[[324  25  20  20]\n",
      " [ 31 306  38  19]\n",
      " [ 19  39 279  55]\n",
      " [ 16  23  61 285]]\n",
      "Accuracy:0.7653846153846153\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(test_labels,predict_test))\n",
    "print (\"Confusion Matrix:\\n{}\".format(confusion_matrix(test_labels,predict_test)))\n",
    "print (\"Accuracy:{}\".format(np.average(test_labels == predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression- No feature transformation, default params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           comp.graphics       0.84      0.89      0.87       389\n",
      " comp.os.ms-windows.misc       0.86      0.76      0.81       394\n",
      "comp.sys.ibm.pc.hardware       0.82      0.79      0.81       392\n",
      "   comp.sys.mac.hardware       0.83      0.90      0.86       385\n",
      "\n",
      "               micro avg       0.84      0.84      0.84      1560\n",
      "               macro avg       0.84      0.84      0.84      1560\n",
      "            weighted avg       0.84      0.84      0.84      1560\n",
      "\n",
      "Confusion Matrix:\n",
      "[[347  13  13  16]\n",
      " [ 39 301  35  19]\n",
      " [ 17  29 311  35]\n",
      " [ 10   9  20 346]]\n",
      "Accuracy:0.8365384615384616\n"
     ]
    }
   ],
   "source": [
    "classifier = logreg_model(C = 3)\n",
    "classifier.train(train_tfidf,train_labels)\n",
    "\n",
    "predict_test = classifier.predict(test_tfidf)\n",
    "\n",
    "print (classification_report(test_labels,predict_test))\n",
    "print (\"Confusion Matrix:\\n{}\".format(confusion_matrix(test_labels,predict_test)))\n",
    "print (\"Accuracy:{}\".format(np.average(test_labels == predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. C = 5, NPC = 2343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVM(C = 10)\n",
    "classifier.train(train_PC,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = classifier.predict(test_PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1560,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           comp.graphics       0.00      0.00      0.00       389\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00       394\n",
      "comp.sys.ibm.pc.hardware       0.25      1.00      0.40       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "\n",
      "               micro avg       0.25      0.25      0.25      1560\n",
      "               macro avg       0.06      0.25      0.10      1560\n",
      "            weighted avg       0.06      0.25      0.10      1560\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   0 389   0]\n",
      " [  0   0 394   0]\n",
      " [  0   0 392   0]\n",
      " [  0   0 385   0]]\n",
      "Accuracy:0.2512820512820513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Associate\\Anaconda3\\envs\\text_cla\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(test_labels,predict_test))\n",
    "print (\"Confusion Matrix:\\n{}\".format(confusion_matrix(test_labels,predict_test)))\n",
    "print (\"Accuracy:{}\".format(np.average(test_labels == predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comp.sys.ibm.pc.hardware', 'comp.sys.ibm.pc.hardware',\n",
       "       'comp.sys.ibm.pc.hardware', ..., 'comp.sys.ibm.pc.hardware',\n",
       "       'comp.sys.ibm.pc.hardware', 'comp.sys.ibm.pc.hardware'],\n",
       "      dtype='<U24')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
