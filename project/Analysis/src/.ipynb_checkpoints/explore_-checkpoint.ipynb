{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Collecting nltk',\n",
       " '  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)',\n",
       " 'Requirement already satisfied: six in c:\\\\users\\\\associate\\\\anaconda3\\\\envs\\\\text_cla\\\\lib\\\\site-packages (from nltk) (1.12.0)',\n",
       " 'Collecting singledispatch (from nltk)',\n",
       " '  Downloading https://files.pythonhosted.org/packages/c5/10/369f50bcd4621b263927b0a1519987a04383d4a98fb10438042ad410cf88/singledispatch-3.4.0.3-py2.py3-none-any.whl',\n",
       " 'Building wheels for collected packages: nltk',\n",
       " '  Building wheel for nltk (setup.py): started',\n",
       " \"  Building wheel for nltk (setup.py): finished with status 'done'\",\n",
       " '  Stored in directory: C:\\\\Users\\\\Associate\\\\AppData\\\\Local\\\\pip\\\\Cache\\\\wheels\\\\4b\\\\c8\\\\24\\\\b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e',\n",
       " 'Successfully built nltk',\n",
       " 'Installing collected packages: singledispatch, nltk',\n",
       " 'Successfully installed nltk-3.4 singledispatch-3.4.0.3']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%system\n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = clean_data.data\n",
    "testX = data['test'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: stimpy@dev-null.phys.psu.edu (Gregory Nagy)\\nSubject: Re: ESPN UP YOURS .........\\nOrganization: Penn State Laboratory for Elementary Steam Physics\\nLines: 52\\nNNTP-Posting-Host: dev-null.phys.psu.edu\\n\\nIn article <C5u542.3CD@news.udel.edu> tmavor@earthview.cms.udel.edu writes:\\n>>\\n>>[Various justifiable rantings on ESPN coverage by several deleted]\\n>>\\n>\\n>The only way to change ESPN\\'s thinking, if it is even possible, is to complain\\n>to them directly.  Anyone know there telephone # in Bristol, Ct?  \\n\\nHeh... Try the rec.autos.sport FAQ. They are always calling ESPN to complain.\\nI\\'m sure you could find the number for ABC there too, as many west-coast \\nviewers were compaining about how something as boring as hockey cut into\\nthe Long Beach GP. =)\\n\\n>\\n>I do find it hard to believe that ESPN doesn\\'t think viewers will simply\\n>change the channel from a boring game....I know I did.  And then, when\\n>they didn\\'t show the NYI-Wash overtime(s), I was livid!  If I wanted\\n>to watch baseball, I could have turned on the Phillies-Padres extra\\n>inning game....instead, I went to bed angry......I boycotted ESPN\\'s\\n>morning Sportscenter today, I was still so incensed.\\n\\nWere you (and several of the other people here it seems) asleep the day\\n\"contracts\" were explained? ASPN has a piece of paper saying it MUST\\nshow that baseball game if it happens. Many businesses payedd money to\\nhave their commercials run during a baseball game. This is a business,\\nnot your own personal video servant.\\n\\n>\\n>My wife says I shouldn\\'t go to bed angry, but last nite.........GRRRRRRR!\\n>\\n\\nMaybe you should put that anger into something positive. For example, I saw\\nads for the new Dodge both on the ESPN and KBL broadcasts. Why not write to\\nDodge saying that \"thanks to the ads run during the STANLEY CUP PLAYOFFS, \\nyou will now concider their products in the future. They love to hear stuff\\nlike that and in the future will be more willing to buy commercial time\\nfor hockey games, giving ESPN (and other networks) more incentive to carry\\ngames (just one example)\\n\\nCome on people, as great as we think it is, Hockey does not leapfrog the\\n\"big three\" overight.\\n\\n> \\n>---------------------------------------------------------------------\\n>Tim Mavor\\t\\t   |  \"I am known by many names.......\\n>College of Marine Studies  |   some call me.........Tim.\"\\n>Univ. of Delaware\\t   |    \\n>Newark, DE 19716\\t   |  \"You know much that is hidden, O\\' Tim!\"\\n>tmavor@pandora.cms.udel.edu|  \\tMonty Python and the Holy Grail\\t---------------------------------------------------------------------\\n>\\n\\n\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "stemmer=SnowballStemmer(\"english\")\n",
    "punctuations='[! \\\" # $ % \\& \\' \\( \\) \\ * + , \\- \\. \\/ : ; <=> ? @ \\[ \\\\ \\] ^ _ ` { \\| } ~]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[stemmer.stem(data) for data in re.split(punctuations,data[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"I am kedar\",\"I am   grooot \\n \\t \\r\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am kedar', 'i am  grooot  ']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ad for ad in map(preprocess_text,a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['test']['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load(\"../Data/20news-bydate_py3.pkz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = [data['test'].data[i] for i in range(len(data['test'].data)) if \\\n",
    "     (data['test'].target_names)[data['test'].target[i]] in computer_technology_subclasses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [(data['test'].target_names)[data['test'].target[i]] for i in range(len(data['test'].data)) if \\\n",
    "     (data['test'].target_names)[data['test'].target[i]] in computer_technology_subclasses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = computer_technology_subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = [data['train'].data[i] for i in range(len(data['train'].data)) if \\\n",
    "(data['train'].target_names)[data['train'].target[i]] in classes]\n",
    "\n",
    "train_labels = [(data['train'].target_names)[data['train'].target[i]] \\\n",
    "for i in range(len(data['train'].data)) if \\\n",
    "(data['train'].target_names)[data['train'].target[i]] in classes]\n",
    "\n",
    "test_text = [data['test'].data[i] for i in range(len(data['test'].data)) if \\\n",
    "(data['test'].target_names)[data['test'].target[i]] in classes]\n",
    "\n",
    "test_labels = [(data['test'].target_names)[data['test'].target[i]] \\\n",
    "for i in range(len(data['test'].data)) if \\\n",
    "(data['test'].target_names)[data['test'].target[i]] in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text,train_labels= c['arr_0'], c['arr_1']\n",
    "test_text,test_labels = c['arr_2'], c['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = [ad for ad in map(preprocess_text,test_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"--\" in \"\".join(test_text[i].split(\"\\n\\n\")[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Lots of stuff deleted because I felt like it ]This MS bashing has definitely lost all its humor value.I think most of the people posting are forgetting that most users\n",
      "of MS products do not even know about internet, and Unix is that\n",
      "very unfriendly place where bizzare abreviations replace the rather\n",
      "comfortable abreviations they know. And the abreviations have subtle\n",
      "differences between the different vendors. While PC users tend to\n",
      "customize any windowing setup, they can not do much with their \n",
      "command line.So to most of the computer users in the world MS product symbolize\n",
      "quality. MS has made their life easier, and more productive and to them\n",
      "that is quality. They do not care about what innovative things MS has\n",
      "done, other than to make their life with a computer one heck of a lot\n",
      "easier. You may know better than most computer users in this world\n",
      "but that will not change their perception.Face it until Unix come up with a decent GUI that is available to\n",
      "all variations of Unix it just will not catch on with the mainstream\n",
      "of computer users. We here on the net are not mainstream computer users.\n",
      "Brian\n",
      "-- Disclaimer: The opinions expressed are mine not those of BNR. ____________________________________________________________________________\n",
      "| Brian, WS1S (ST/TT User/Developer) |  If I wanted a computer to play games |\n",
      "| Bell Northern Research             |  on I'd buy an Amiga. However I have  |\n",
      "| Research Triangle Park, NC         |  real work to do. So please get lost! |\n",
      "|____________________________________|_______________________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(test_text[i].split(\"\\n\\n\")[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(\"\".join(test_text[i].split(\"\\n\\n\")[1:]).split(\"--\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Michael.B.Taylor@dartmouth.edu (Michael B. Taylor)\n",
      "Subject: new 1 gig SCSI-2 3.5\" 5400 rpm drives - Ratings?\n",
      "X-Posted-From: InterNews 1.0b15@dartmouth.edu\n",
      "Organization: Dartmouth College, Hanover, NH\n",
      "Lines: 16\n",
      "\n",
      "I've noticed a recent proliferation of 1 gig SCSI-2 3.5\" drives, in\n",
      "particular, the Fujitsu 2694 and the Micropolis 2112. There is also the\n",
      "Maxtor LXT1240s (6100 rpm, 1.2 gig) drive. They are all quite cheap,\n",
      "and have nice 3-5 year warranties. \n",
      "\n",
      "My questions are: Is there a catch?\n",
      "                  Which one is better?\n",
      "                  What type of SCSI-2 do these drives use?\n",
      "                  Is the service generally better for one of these     \n",
      "         \n",
      "                  manufacturers?\n",
      "                  Are prices likely to go down soon for any reason?\n",
      "\n",
      "thanks,\n",
      "\n",
      "Michael Taylor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (test_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: Michael.B.Taylor@dartmouth.edu (Michael B. Taylor)\\nSubject: new 1 gig SCSI-2 3.5\" 5400 rpm drives - Ratings?\\nX-Posted-From: InterNews 1.0b15@dartmouth.edu\\nOrganization: Dartmouth College, Hanover, NH\\nLines: 16\\n\\nI\\'ve noticed a recent proliferation of 1 gig SCSI-2 3.5\" drives, in\\nparticular, the Fujitsu 2694 and the Micropolis 2112. There is also the\\nMaxtor LXT1240s (6100 rpm, 1.2 gig) drive. They are all quite cheap,\\nand have nice 3-5 year warranties. \\n\\nMy questions are: Is there a catch?\\n                  Which one is better?\\n                  What type of SCSI-2 do these drives use?\\n                  Is the service generally better for one of these     \\n         \\n                  manufacturers?\\n                  Are prices likely to go down soon for any reason?\\n\\nthanks,\\n\\nMichael Taylor\\n'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = CountVectorizer(min_df=2,stop_words ='english')\n",
    "transformer.fit(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "vocabulary_ not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-265-f2b834c969d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\text_cla\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: vocabulary_ not found"
     ]
    }
   ],
   "source": [
    "transformer.transform(test_text).vocabulary_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
