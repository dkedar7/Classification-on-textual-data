{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Collecting nltk',\n",
       " '  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)',\n",
       " 'Requirement already satisfied: six in c:\\\\users\\\\associate\\\\anaconda3\\\\envs\\\\text_cla\\\\lib\\\\site-packages (from nltk) (1.12.0)',\n",
       " 'Collecting singledispatch (from nltk)',\n",
       " '  Downloading https://files.pythonhosted.org/packages/c5/10/369f50bcd4621b263927b0a1519987a04383d4a98fb10438042ad410cf88/singledispatch-3.4.0.3-py2.py3-none-any.whl',\n",
       " 'Building wheels for collected packages: nltk',\n",
       " '  Building wheel for nltk (setup.py): started',\n",
       " \"  Building wheel for nltk (setup.py): finished with status 'done'\",\n",
       " '  Stored in directory: C:\\\\Users\\\\Associate\\\\AppData\\\\Local\\\\pip\\\\Cache\\\\wheels\\\\4b\\\\c8\\\\24\\\\b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e',\n",
       " 'Successfully built nltk',\n",
       " 'Installing collected packages: singledispatch, nltk',\n",
       " 'Successfully installed nltk-3.4 singledispatch-3.4.0.3']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%system\n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = clean_data.data\n",
    "testX = data['test'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: stimpy@dev-null.phys.psu.edu (Gregory Nagy)\\nSubject: Re: ESPN UP YOURS .........\\nOrganization: Penn State Laboratory for Elementary Steam Physics\\nLines: 52\\nNNTP-Posting-Host: dev-null.phys.psu.edu\\n\\nIn article <C5u542.3CD@news.udel.edu> tmavor@earthview.cms.udel.edu writes:\\n>>\\n>>[Various justifiable rantings on ESPN coverage by several deleted]\\n>>\\n>\\n>The only way to change ESPN\\'s thinking, if it is even possible, is to complain\\n>to them directly.  Anyone know there telephone # in Bristol, Ct?  \\n\\nHeh... Try the rec.autos.sport FAQ. They are always calling ESPN to complain.\\nI\\'m sure you could find the number for ABC there too, as many west-coast \\nviewers were compaining about how something as boring as hockey cut into\\nthe Long Beach GP. =)\\n\\n>\\n>I do find it hard to believe that ESPN doesn\\'t think viewers will simply\\n>change the channel from a boring game....I know I did.  And then, when\\n>they didn\\'t show the NYI-Wash overtime(s), I was livid!  If I wanted\\n>to watch baseball, I could have turned on the Phillies-Padres extra\\n>inning game....instead, I went to bed angry......I boycotted ESPN\\'s\\n>morning Sportscenter today, I was still so incensed.\\n\\nWere you (and several of the other people here it seems) asleep the day\\n\"contracts\" were explained? ASPN has a piece of paper saying it MUST\\nshow that baseball game if it happens. Many businesses payedd money to\\nhave their commercials run during a baseball game. This is a business,\\nnot your own personal video servant.\\n\\n>\\n>My wife says I shouldn\\'t go to bed angry, but last nite.........GRRRRRRR!\\n>\\n\\nMaybe you should put that anger into something positive. For example, I saw\\nads for the new Dodge both on the ESPN and KBL broadcasts. Why not write to\\nDodge saying that \"thanks to the ads run during the STANLEY CUP PLAYOFFS, \\nyou will now concider their products in the future. They love to hear stuff\\nlike that and in the future will be more willing to buy commercial time\\nfor hockey games, giving ESPN (and other networks) more incentive to carry\\ngames (just one example)\\n\\nCome on people, as great as we think it is, Hockey does not leapfrog the\\n\"big three\" overight.\\n\\n> \\n>---------------------------------------------------------------------\\n>Tim Mavor\\t\\t   |  \"I am known by many names.......\\n>College of Marine Studies  |   some call me.........Tim.\"\\n>Univ. of Delaware\\t   |    \\n>Newark, DE 19716\\t   |  \"You know much that is hidden, O\\' Tim!\"\\n>tmavor@pandora.cms.udel.edu|  \\tMonty Python and the Holy Grail\\t---------------------------------------------------------------------\\n>\\n\\n\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "stemmer=SnowballStemmer(\"english\")\n",
    "punctuations='[! \\\" # $ % \\& \\' \\( \\) \\ * + , \\- \\. \\/ : ; <=> ? @ \\[ \\\\ \\] ^ _ ` { \\| } ~]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[stemmer.stem(data) for data in re.split(punctuations,data[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"I am kedar\",\"I am   grooot \\n \\t \\r\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am kedar', 'i am  grooot  ']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ad for ad in map(preprocess_text,a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['test']['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load(\"../Data/20news-bydate_py3.pkz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = [data['test'].data[i] for i in range(len(data['test'].data)) if \\\n",
    "     (data['test'].target_names)[data['test'].target[i]] in computer_technology_subclasses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [(data['test'].target_names)[data['test'].target[i]] for i in range(len(data['test'].data)) if \\\n",
    "     (data['test'].target_names)[data['test'].target[i]] in computer_technology_subclasses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = computer_technology_subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = [data['train'].data[i] for i in range(len(data['train'].data)) if \\\n",
    "(data['train'].target_names)[data['train'].target[i]] in classes]\n",
    "\n",
    "train_labels = [(data['train'].target_names)[data['train'].target[i]] \\\n",
    "for i in range(len(data['train'].data)) if \\\n",
    "(data['train'].target_names)[data['train'].target[i]] in classes]\n",
    "\n",
    "test_text = [data['test'].data[i] for i in range(len(data['test'].data)) if \\\n",
    "(data['test'].target_names)[data['test'].target[i]] in classes]\n",
    "\n",
    "test_labels = [(data['test'].target_names)[data['test'].target[i]] \\\n",
    "for i in range(len(data['test'].data)) if \\\n",
    "(data['test'].target_names)[data['test'].target[i]] in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text,train_labels= c['arr_0'], c['arr_1']\n",
    "test_text,test_labels = c['arr_2'], c['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = [ad for ad in map(preprocess_text,test_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"--\" in \"\".join(test_text[i].split(\"\\n\\n\")[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(\"\".join(test_text[i].split(\"\\n\\n\")[1:]).split(\"--\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%system\n",
    "python clean_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"../Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = np.load(\"../Data/vectorized_data\")\n",
    "except:\n",
    "    os.system(\"python clean_data.py\")\n",
    "    data = np.load(\"../Data/vectorized_data\")\n",
    "    \n",
    "train_text,train_labels = data['arr_0'], data['arr_1']\n",
    "test_text,test_labels = data['arr_2'], data['arr_3']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
